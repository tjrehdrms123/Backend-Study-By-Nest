![](/study/assets/thumbnail_node.png)

# Node.js 크롤링(스크래핑)하기 with Cheerio

### 로직 설계

1. 크롤러 파일 실행
2. 크롤링할 페이지에 있는 게시글 리스트 URL 가져오기
3. 게시글 URL리스트로 들어가 필요한 제목, 설명 데이터 추출
4. DB 연결
5. 추출한 값 DB에 insert

### 크롤링할 데이터

- 게시글 제목
- 게시글 내용
- 게시글 글 주소

### 작업을 위한 패키지 설치

기본 패키지

- nodemon
- typescript

크롤링을 위한 패키지

- axios
- cheerio

추출한 값을 DB에 넣기위한 패키지

- mysql2

### package.json 설명

- npm run dev: 개발 중인 크롤러 파일 실행
- npm run build: 개발 완료 후 크롤로 파일 빌드
- npm run start: 필드된 파일 실행

```json
{
  "name": "app",
  "version": "1.0.0",
  "description": "",
  "main": "crawler.js",
  "scripts": {
    "start": "node dist/crawler.js",
    "build": "tsc -p .",
    "dev": "nodemon --watch \"app/**/*.ts\" --exec \"ts-node\" crawler.ts"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "axios": "^1.2.0",
    "cheerio": "^1.0.0-rc.12",
    "dotenv": "^16.0.3",
    "mysql2": "^2.3.3",
    "nodemon": "^2.0.20",
    "typescript": "^4.9.3"
  },
  "devDependencies": {
    "@types/node": "^18.11.9",
    "ts-node": "^10.9.1"
  }
}
```

### 핵심 파일,폴더 구조

- crawler.ts: 크롤링을하는 메인 파일
- config: 설정 폴더
  - dbconfig.ts: DB 설정 파일
- model: 모델 폴더
  - repository.ts
- type: 타입 폴더
  - type.ts: 타입 interface 폴더

### config/dbconfig.ts

mysql 연결을 위한 dbconfig 파일 구성합니다.

```js
const mysql = require("mysql2/promise");
import "dotenv/config";
const db = mysql.createPool({
  host: process.env.DBHOST,
  user: process.env.DBUSER,
  password: process.env.DBPW,
  database: process.env.DBNAME,
  connectTimeout: 5000,
  connectionLimit: 10, //default 10
});

export { db };
```

### type/type.ts

type interface 설정합니다.

```js
export interface addInformationReq {
  table: string
  key1: string,
  key2: string,
  key3: string,
  value1: string,
  value2: string,
  value3: string,
}
```

### repository.ts

넘겨받을 매개변수에 생성했던 `addInformationReq` 인터페이스를 정의 합니다.

작성 되어있는 코드에서 주의깊게 봐야될 부분은 `finally`부분에 있는 `conn.release()`입니다. 해당 코드가 없다면 `Too many connections에러`가 발생합니다 자세한 부분은 아래 링크를 참고 부탁드립니다.

- [Too many connections에러](/study/JS/Node.js/Error/mysql2%20with%20%E2%80%9CToo%20many%20connections%E2%80%9D.md)

```js
import { db } from "../config/dbconfig";
import { addInformationReq } from "../type/typerepository";

async function addInformation(req: addInformationReq) {
  const { table, key1, key2, key3, value1, value2, value3 } = req;
  let conn = await db.getConnection();
  try {
    let sql = `INSERT INTO ${table}(${key1}, ${key2}, ${key3}) VALUES("${value1}", "${value2}", "${value3}")`;
    await conn.query(sql);
  } catch (err) {
    console.log(err);
  } finally {
    conn.release();
  }
}

export { addInformation };
```

### crawler.ts

로직 설계의 2번과 3을 위한 코드입니다.

- 크롤링할 페이지에 있는 게시글 리스트 URL 가져오기
- 게시글 URL리스트로 들어가 필요한 제목, 설명 데이터 추출

```js
import axios from "axios";
import cheerio from "cheerio";
import { addInformation } from "./model/repository";

(async () => {
  try {
    let result = {
      data: [],
    };
    let conn = null;
    const { tatgetUrl } = process.env;
    const web = await axios.get(targetUrl);
    // 1) 목록 url 얻어오기
    const $ = cheerio.load(web.data);
    $(".r_list li > a").each((idx, dom) => {
      const url = $(dom).attr("href");
      result.data[idx] = { url: `${targetUrl}${url}` };
    });
    // 2) 얻어온 url 목록을 바탕으로 원하는 값 추출
    for (let i = 0; i < result.data.length; i++) {
      const web = await axios.get(result.data[i].url);
      const $ = cheerio.load(web.data);
      $(".board_view > .bv_t > .fl_l > p").each((idx, dom) => {
        const title = $(dom).text();
        result.data[i] = {
          ...result.data[i],
          title: title,
        };
      });
      $(".board_view > .bv_cp > p:nth-child(2)").each((idx, dom) => {
        const description = $(dom).text();
        result.data[i] = {
          ...result.data[i],
          description: description,
        };
      });
      let req = {
        table: "Reservation",
        key1: "title",
        key2: "des",
        key3: "originurl",
        value1: `${result.data[i].title}`,
        value2: `${result.data[i].description}`,
        value3: `${result.data[i].url}`,
      };
      addInformation(req);
    }
  } catch (error) {
    console.log("error: ", error);
  }
})();
```

### 결과

결과는 아래의 형식으로 DB에 들어갑니다.

```sql
(1, '게시글 제목', '게시글 내용', '게시글 글 주소'),
```
